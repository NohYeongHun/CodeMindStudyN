# 시간 복잡도
소스 1에서는 for문을 활용하여 직접 res에 1에서 N까지를 더해서 합을 계산했다. 그리고 소스 2에서는 1에서 N까지 자연수들의 합은 n(n+1)2인 수학 공식을 이용하여 합을 계산했다. 소스 1의 경우에는 N=1,000이라면 덧셈이 1,000번 일어나고, N=1,000,000이라면 덧셈이 1,000,000번 일어나게 된다. 계산하는 횟수가 N에 비례하는 것이다. 반면에, 소스 2에서는 N=1,000이든, N=1,000,000이든 무조건 덧셈 한 번과 곱셈 한 번, 나눗셈 한 번만을 하게 된다. N에 아무 관계 없는 상수 시간 안에 계산이 처리되는 것이다.

모든 알고리즘은 이와 같이 입력되는 데이터의 크기 또는 갯수에 따라 이의 계산 횟수[1]수행 시간이 크게 달라지게 된다. 입력받는 데이터의 크기에 따른 알고리즘의 수행시간의 변화가 시간복잡도이다. 시간복잡도가 더 큰 알고리즘들은 더 큰, 혹은 많은 데이터를 처리할 때 훨씬 더 오랜 시간이 걸리게 된다. 그런데 이 계산 횟수의 정확한 측정이 어렵기 때문에, 보통 Big O 표기법이라는 걸 이용해서 표시한다.

입력된 데이터의 갯수가 n개일 때 2n+7번 계산하는 알고리즘과 2n번 계산하는 알고리즘이 있다고 하자. n이 커지면 둘 사이의 차이는 사실상 없어진다. 이를 O 표기법으로 나타내면 O(2n+7)=O(2n)이다. 대략 O 표기법은 상수만큼의 시간 차이는 무시하는 것이라고 생각할 수 있겠다. [2]

크기 n의 데이터가 들어올 때 n2번 계산해서 답을 내는 알고리즘과 1,000n번 계산해서 답을 내는 알고리즘을 비교해 보자. n=10일 때는 1,000n번 계산하는 알고리즘이 100배 더 느릴지 모르지만, n=1,000만 되어도 두 알고리즘의 속도가 비슷해지고, n=100,000인 경우에는 n2번 계산하는 알고리즘이 100배나 더 느려진다.

n=10 정도의 작은 데이터에서는 100배 더 느리다고 해도 불과 0.0001초 정도밖에 차이가 나지 않을 것이다. 데이터의 크기가 적으므로 두 프로그램 모두 매우 빠르기 때문이다! 하지만 n=100,000에서는 100배의 차이는 생각하는 것만큼 매우 크다. 1000n번 계산하는 프로그램이 0.3초간 계산해서 답을 내놓는 사이에, n2번 계산하는 프로그램은 30초는 생각해야 답을 내놓을 수 있을 것이다. n=1,000,000라던지, n=10,000,000와 같은 식으로 n이 더더욱 커지면 어떻게 될까? 두 프로그램의 시간 차이는 기하급수적으로 커지게 될 것이다.

위의 예시에서 알 수 있었던 것은 계산 횟수에 붙은 상수는 별로 중요하지 않다는 것이다. 1,000이라는 상수가 무색해질 정도로 n이 커지면, 그 때는 n이 커짐에 따라 증가하는 계산 횟수가 훨씬 더 중요해진다.[3] 그래서 시간복잡도를 나타낼 때에는 상수는 모두 떼어버리기로 하자. n번 계산하든, 7n+1312번 계산하든, 142857n번 계산하든 모두 O(n)로 나타내는 것이다! 비슷한 이유로, 3n+2n3+12451n2+33nlogn+151511번 계산[4]하는 알고리즘의 시간 복잡도는 O(2n)[5]로 간단히 나타낼 수 있다.

위의 소스들의 시간 복잡도는 어떻게 쓸 수 있을까? 소스 1은 O(N)의 시간 복잡도를, 소스 2는 O(1)의 시간 복잡도를 가지게 된다는 것을 알 수 있다. 직관적으로도 알 수 있듯이, O(1)의 알고리즘이 O(N)의 알고리즘보다 더 빠른 알고리즘이라고 할 수 있다.

자주 등장하는 알고리즘의 시간 복잡도는 아래와 같다. 위의 알고리즘이 가장 시간 복잡도가 낮은, 즉 가장 빠른 알고리즘이라고 부르고, 아래의 알고리즘이 가장 시간 복잡도가 높은, 즉 가장 느린 알고리즘이라 부른다.

# 시간 복잡도	설명
O(1)	상수 형태. n의 값에 상관없이 일정한 양의 계산만 한다.
O(logn)	로그 형태
O(n)	선형
O(nlogn)	선형로그 형태
O(n^2),O(n^3),⋯	다차 형태
O(2^n) 지수 형태
O(n!)	팩토리얼 형태

# 시간 복잡도 계산해보기
프로그래밍 대회에서 문제를 풀 때에는 프로그램 수행 시간의 제한이 있기 때문에, 일정한 시간 복잡도 이하가 되어야 정답, 즉 Accepted 판정이 된다. 이 때 필요한 시간 복잡도를 대략 계산해 보려면 문제에서 N의 제한을 보면 된다. 당신이 짠 프로그램의 시간 복잡도에 실제 N의 제한을 넣어 보자. 이 수가 대략 1천만 ~ 10억 사이일 때 대략 1초의 시간 제한에 맞는 프로그램이라 할 수 있다. 만약, 당신이 짠 프로그램의 시간 복잡도가 O(n2logn)이고, n의 제한이 n≤1,000이라고 하자. 이 때 n의 제한인 1,000을 실제로 식에 넣어보는 것이다. 10002log1000=10,000,000[7]이므로, 상수가 너무 크지 않으면, 즉 안에 들어가 있는 계산량이 너무 많지 않은 이상은 1초의 시간 제한 안에 돌아가게 될 것이다.

# reference
  [자료구조개념] https://librewiki.net/wiki/%EC%8B%9C%EB%A6%AC%EC%A6%88:%EC%88%98%ED%95%99%EC%9D%B8%EB%93%AF_%EA%B3%BC%ED%95%99%EC%95%84%EB%8B%8C_%EA%B3%B5%ED%95%99%EA%B0%99%EC%9D%80_%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B3%BC%ED%95%99/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_%EA%B8%B0%EC%B4%88